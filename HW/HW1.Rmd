---
title: "STAT 5370 â€“ Decision Theory"
subtitle: "Homework 1"
author: "Matthew Aaron Looney"
date: "6/9/2018"
output: pdf_document
---

```{r, echo=F, warning=F, message=F, cache=T}

# Housekeeping ----------------------------------------------------------------
rm(list=ls())
cat("\014")
#library(datasets)
#data(faithful)
library(feather)
library(dplyr)

# Load Data -------------------------------------------------------------------
LA_data_2010 <- read_feather("/Users/malooney/Google Drive/digitalLibrary/*MS_Thesis/MS_Thesis/data/LA_data_2010_feather")

# Add volume measures ---------------------------------------------------------
oz <- round(data.frame(oz=LA_data_2010$VOL_EQ.x* 288))
total_oz <- (oz* LA_data_2010$UNITS); 
colnames(total_oz) <- "total_oz"
total_gal <- (0.0078125* total_oz); 
colnames(total_gal) <- "total_gal"
dollarPerGal <- LA_data_2010$DOLLARS/ total_gal; 
colnames(dollarPerGal) <- "dollarPerGal"

LA_data_2010_manip <- cbind(LA_data_2010, oz, total_oz, total_gal, 
                            dollarPerGal)

rm(oz, total_gal, total_oz, dollarPerGal, LA_data_2010)

# Remove zero data ------------------------------------------------------------
LA_data_2010_manip <- filter(LA_data_2010_manip, L5 !="ALL BRAND")
LA_data_2010_manip <- filter(LA_data_2010_manip, dollarPerGal !="Inf")

# Explore Brands, Firms, and percenatges of Brands by Firms -------------------
#uniqueBrands <- data.frame(table(LA_data_2010_manip$L5))
#uniqueBrands <- arrange(uniqueBrands, desc(Freq))
#(sum(uniqueBrands[1:20,2]) / nrow(LA_data_2010_manip)) * 100

#uniqueBrands_all <- data.frame(Brand = rep(LA_data_2010_manip$L5, 
#                                       LA_data_2010_manip$UNITS), 
#                           y = sequence(LA_data_2010_manip$UNITS))

#uniqueBrands <- data.frame(table(uniqueBrands_all$Brand))
#uniqueBrands <- arrange(uniqueBrands, desc(Freq))
#prcntBrandRep <- (sum(uniqueBrands[1:60,2]) / nrow(uniqueBrands_all)) * 100

#uniqueChains <- data.frame(table(LA_data_2010_manip$MskdName))
#uniqueChains <- arrange(uniqueChains, desc(Freq))
#uniqueFirms <- data.frame(table(LA_data_2010_manip$L4))
#uniqueFirms <- arrange(uniqueFirms, desc(Freq))
#uniqueConglomerates <- data.frame(table(LA_data_2010_manip$L3))
#uniqueConglomerates <- arrange(uniqueConglomerates, desc(Freq))

#rm(uniqueBrands_all)

uniqueWeeks <- unique(LA_data_2010_manip$WEEK)

LA_data_2010_manip1 <- filter(LA_data_2010_manip, MskdName=="Chain79")
LA_data_2010_manip2 <- filter(LA_data_2010_manip1, L5=="ANCHOR STEAM BEER")
LA_data_2010_manip3 <- filter(LA_data_2010_manip2, upc=="00-01-72783-00100")


mainData <- data.frame(week=c(1:52), units = c(1:52), gallons = c(1:52), 
                       `Calendar week starting on` = c(1:52), 
                       weekNum = uniqueWeeks)

for(i in 1:length(uniqueWeeks)){
  temp <- filter(LA_data_2010_manip3, WEEK== uniqueWeeks[i])
  temp1 <- sum(temp$UNITS)
  temp2 <- sum(temp$total_gal)
  mainData[i,2] <- temp1
  mainData[i,3] <- temp2
  mainData[i,4] <- as.character(unique(LA_data_2010_manip$`Calendar week starting on`)[i])
  
}

rm(i, temp, temp1, temp2, uniqueWeeks, LA_data_2010_manip, 
   LA_data_2010_manip1, LA_data_2010_manip2, LA_data_2010_manip3)

```


# Problem 1

In this problem we will consider developing a Bayesian model for Poisson
iid data; i.e., our observed data will consist of $Y_1,...,Y_n \mathop  \sim \limits^{iid} Poisson(\lambda )$. Recall, a random variable $Y$ is said to follow a Poisson distribution, with mean paramater $\lambda$, if its pmf is given by

\begin{equation}
p(y|\lambda ) = \frac{{{e^{ - \lambda }}{\lambda ^y}}}{{y!}}I(y \in \{ 0,1,2,...\} )
\end{equation}

Note, the Poisson model is often used to analyze count data.

### (a)  For the Poisson model, identify the conjugate prior. This should be a general class of priors.

If we assume the Gamma distribution as a prior for the Poisson model: $p(\lambda)=\frac{{{\beta ^\alpha }}}{{\Gamma (\alpha )}}{\lambda^{\alpha  - 1}}{e^{ - \beta \lambda}}  \propto {\lambda^{\alpha  - 1}}{e^{ - \beta \lambda}}$; where $\alpha>0$ (shape paramater) and $\beta>0$ (rate paramater) then this choice of prior is also the conjugate prior for the Poisson model.


### (b)  Under the conjugate prior, derive the posterior distribution of $\lambda|y$. This should be a general expression based on the choice of the hyper-parameters specified in your prior.

To derive the posterior distribution we need the liklihood function associated with the Poisson model:

\begin{equation}
L(\lambda |y) = \prod\limits_{i = 1}^n {\frac{{{e^{ - \lambda }}{\lambda ^y}}}{{y!}}}  = \frac{{{e^{ - n\lambda }}{\lambda ^{\sum\limits_{i = 1}^n {{y_i}} }}}}{{\prod\limits_{i = 1}^n {y!} }}
\end{equation}

In general, the posterior distribution is defined as:

\begin{equation}
p(\lambda |y) = \frac{{p(y|\lambda )p(\lambda )}}{{\int\limits_A {p(y|\lambda )p(\lambda )d\lambda } }} \propto \underbrace {p(y|\lambda )}_{{\text{L(}}\lambda {\text{)}}}\underbrace {p(\lambda )}_{{\text{Prior}}}
\end{equation}

With a Poisson DGP and a Gamma prior the derived posterior distribution is defined by:

\begin{equation}
\begin{aligned}
  p(\lambda | y) &= {e^{ - n\lambda }}{\lambda ^{\sum\limits_{i = 1}^n {{y_i}} }} \cdot {\lambda ^{\alpha  - 1}}{e^{ - \beta \lambda }} \\ 
                 &= {\lambda ^{\sum\limits_{}^{} {{y_i} + \alpha  - 1} }} \cdot {e^{ - (n - \beta )\lambda }} \\ 
\end{aligned}
\end{equation}

The posterior distribution of $\lambda$ under the Gamma prior is $Gamma( {\sum {{y_i}}  + \alpha }, {n + \beta })$, where $\alpha$ and $\beta$ are the hyperparamaters of the Gamma distribution.


### (c)  Find the posterior mean and variance of $\lambda|y$. These should be general expressions based on the choice of the hyper-parameters specified in your prior.

The mean and variance of the Gamma distribution is given by the following expressions: $E(\lambda)=\frac{\alpha}{\beta}$; $Var(\lambda)=\frac{\alpha}{\beta^2}$.

Then the posterior mean and variance  of $\lambda|y$ is:

\begin{equation}
\begin{aligned}
E(\lambda |y) &= \frac{\alpha }{\beta } = \frac{{\sum {{y_i}}  + \alpha }}{{n + \beta }} \\
Var(\lambda |y) &= \frac{\alpha }{{{\beta ^2}}} = \frac{{\sum {{y_i}}  + \alpha }}{{{{(n + \beta )}^2}}}
\end{aligned}
\end{equation}


### (d)   Obtain the MLE of $\lambda$. Develop and discuss a relationship that exists between the MLE and posterior mean identified in (c).

Starting from the Poisson distribution, $p(y|\lambda ) = \frac{{{e^{ - \lambda }}{\lambda ^y}}}{{y!}}$, we obtain the liklihood function:

\[L(\lambda |{y_1},{y_2},...,{y_n}) = \prod\limits_{i = 1}^n {\frac{{{e^{ - \lambda }}{\lambda ^{{y_i}}}}}{{{y_i}!}}} \]

Then, taking log of above equation and taking derivatives we can obtain an expression for $\hat\lambda$:

\begin{equation}
\begin{gathered}
  \log L(\lambda |{x_1},{x_2},...,{x_n}) =  - n\lambda  - \sum\limits_{i = 1}^n {\log ({y_i}!) + \log (\lambda )\sum\limits_{i = 1}^n {{y_i}} }  \hfill \\
  \frac{{\partial \log L( \cdot )}}{{\partial \lambda }} =  - n + \frac{{\sum\limits_{i = 1}^n {{y_i}} }}{\lambda } = 0 \hfill \\
  \hat \lambda  = \frac{{\sum\limits_{i = 1}^n {{y_i}} }}{n} \hfill \\ 
\end{gathered} 
\end{equation}


We can now see that when the hyperparamaters of the posterior mean (part c) are zero the posterior mean collapses to the MLE estimator of $\lambda$. 


### (e)  Write two separate R programs which can be used to find both a (1-$\alpha$)100% equal-tailed credible interval and a (1-$\alpha$)100% HPD credible interval for the Poisson model. These programs should take as arguments the following inputs: the observed data, prior hyper-parameters, and significance level.




### (f)  Find a data set which could be appropriately analyzed using the Poisson model. This data set should be of interest to you, and you should discuss, briefly, why the aforementioned model is appropriate; e.g., consider independence, identically distributed, etc. etc. You will also need to provide the source of the data.

```{r echo=F, fig.height=3.5}

par(mfrow=c(1,2), ps = 10, cex = 0.75, cex.main = 1)

plot(x = mainData[,1], y = mainData[,2], type="l", 
     main="Unit of Beer Sold per Week", 
     xlab="Week", 
     ylab="Units")

hist(mainData[,2], main="Histogram of Unit of Beer Sold per Week")

```



### (g)  Analyze the data set you have selected in (e). Provide posterior point estimates of $\lambda$, credible intervals, etc. etc. Your analysis should be accompanied by an appropriate discussion of your findings.

```{r, echo=F, fig.height=7}

par(mfrow=c(2,2), ps = 10, cex = 0.75, cex.main = 1)


# Beer data -------------------------------------------------------------------
sum_y = sum(mainData$units)
n = length(mainData$units)
mu_y.Freq <- mean(mainData$units)
var_y.Freq <- var(mainData$units)

# prior and posterior ---------------------------------------------------------
mu_0 <- 4
sigma2_0 <-8

b0 <- mu_0 / sigma2_0
a0 <- mu_0 * b0

grid = seq(0.1, 20, length=10000)

grid.priorpmf = dgamma(grid, shape = a0, rate = b0)

priorpmf.grid = dgamma(grid, shape=a0, rate=b0)

# Plot Prior ------------------------------------------------------------------
plot(grid, priorpmf.grid,
     col='red', type="l", 
     main="Prior Density", xlab=expression(lambda), ylab="density")

lines(density(mainData$units), lty=2)

legend(12, .18,  c("Prior", "Data"), lty=c(1,2), col=c("red", "black"))

# Plot Likelihood -------------------------------------------------------------
likelihood.grid = dpois(sum_y, lambda = n * grid, log=F)

plot(x = grid, y = likelihood.grid,
     main="Likelihood of Lambda", 
     col='green',type="l", 
     xlab=  expression(lambda), 
     ylab= expression(L(lambda)))

# posterior parameters --------------------------------------------------------
a1= a0 + sum_y
b1 = b0 + n

posteriorpmf.grid=dgamma(grid,shape= a1, rate= b1)

# Plot Posterior --------------------------------------------------------------
plot(grid, posteriorpmf.grid,
     main="Posterior Density",  ylab="density", col='blue', type="l",
     xlab=expression(lambda))

# Plot densities together -----------------------------------------------------
plot(grid, posteriorpmf.grid, ylab="density",
     main="Densities \n Gamma Prior/Posterior (red/blue)\n",
     type="n", xlab=expression(lambda))

lines(grid, priorpmf.grid, col='red') # prior

lines(grid, posteriorpmf.grid, col='blue') # posterior

lines(density(mainData$units), lty=2) # data

lines(grid, 20*likelihood.grid, col="green") # liklihood

legend(10, 1.35,  c("Prior", "Data", "Likelihood", "Posterior"), 
       lty=c(1,2,1, 1), col=c("red", "black", "green", "blue"))


posterior.mean = a1/b1
posterior.var = a1/b1^2

# #     Add case of Uniform prior ----
# lines(lambda.grid, (1 + 0 * priorpmf.grid) * 0.1 / 30, col='orange')
# posteriorpmf.uniformprior.grid = dgamma(lambda.grid, shape = 1 + sum_y,
#                                         rate= n)
# 
# lines(lambda.grid, posteriorpmf.uniformprior.grid, col='green')
# 
# title(main="\n\nUniform Prior/Posterior (orange/green)")

#########################################
## Quantile-based intervals
qgamma(c(0.025, 0.975), a1, b1)

```





